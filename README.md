# Proto-Bench

HTTP vs gRPC 프로토콜 성능 비교 벤치마크 프로젝트

## 프로젝트 목적

동일한 조건에서 HTTP와 gRPC의 실제 성능 차이를 측정하고 수치화합니다. 다양한 조건(페이로드 크기, 동시 사용자 수, 데이터 복잡도)에서 각 프로토콜의 성능 특성을 분석하여 실무에서의 프로토콜 선택 가이드를 제공합니다.

## 아키텍처

```
┌─────────┐      ┌─────────────┐      ┌─────────────┐
│   k6    │ ──── │  apiServer  │ ──── │ dataServer  │
│ (Load)  │      │  (Gateway)  │      │  (Data Gen) │
└─────────┘      └─────────────┘      └─────────────┘
                       │                     │
                 HTTP or gRPC          HTTP or gRPC
```

## 기술 스택

- **Language**: Kotlin
- **Framework**: Spring Boot 3.x
- **gRPC**: grpc-kotlin
- **Build**: Gradle (Kotlin DSL)
- **Load Test**: k6 (Grafana)

---

## 📊 전체 벤치마크 결과 요약

### 프로토콜 선택 가이드

| 조건 | 추천 프로토콜 | 성능 차이 | 근거 |
|------|--------------|----------|------|
| **소용량 API (≤100KB)** | gRPC/Unary | 30~67% 더 빠름 | Protobuf 효율 + HTTP 헤더 오버헤드 절감 |
| **대용량 전송 (≥200KB)** | HTTP/Binary | 14~60% 더 빠름 | 직렬화 오버헤드 없음 |
| **고동시성 (200+ VU)** | gRPC/Unary | 9~12% 더 빠름 | HTTP/2 멀티플렉싱 효과 |
| **저동시성 (< 100 VU)** | HTTP/Binary | 3~13% 더 빠름 | 단순한 프로토콜 |
| **복잡한 구조 (≤50 필드)** | gRPC/Unary | 40~69% 더 빠름 | Protobuf 파싱 효율 |
| **극한 복잡도 (≥150 필드)** | HTTP/Binary | 12~18% 더 빠름 | Protobuf 빌더 오버헤드 |
| **실시간 양방향** | gRPC/Stream | - | 기능적 요구 |

### 핵심 역전 포인트

| 기준 | 역전 포인트 | gRPC 우위 | HTTP 우위 |
|------|------------|----------|----------|
| 페이로드 크기 | 100~200KB | ≤100KB | ≥200KB |
| 동시 사용자 | 100~200 VU | 200+ VU | <100 VU |
| 데이터 복잡도 | ~150 필드 | ≤50 필드 | ≥150 필드 |

---

## 📋 Phase별 상세 결과

### Phase 1: 대용량 단일 페이로드 (1MB)

#### 목적
HTTP와 gRPC 프로토콜의 대용량 데이터(1MB) 전송 성능 비교

#### 가설
> "gRPC는 HTTP/2 기반이고 Protobuf를 사용하므로 HTTP/JSON보다 빠를 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 1MB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 30초 |

#### 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **HTTP/Binary** | **2,506.24** | **2.70ms** | **4.00ms** | 🥇 |
| gRPC/Unary | 1,186.64 | 6.87ms | 11.23ms | 🥈 |
| HTTP/JSON | 514.54 | 17.42ms | 23.81ms | 🥉 |
| gRPC/Stream | 210.72 | 44.53ms | 67.08ms | 4위 |

#### 결론
**가설 기각**: 대용량 단일 페이로드에서는 HTTP/Binary가 gRPC보다 **약 2배 빠름**

#### 원인 분석
- HTTP/Binary: 직렬화 오버헤드 없이 raw bytes 그대로 전송
- gRPC: Protobuf 직렬화/역직렬화 비용 + HTTP/2 프레이밍 오버헤드
- 단일 요청에서는 HTTP/2 멀티플렉싱의 이점이 없음

---

### Phase 2: 소용량 페이로드 (1KB, 10KB)

#### 목적
작은 페이로드에서 HTTP 헤더 오버헤드 영향 검증

#### 가설
> "작은 페이로드에서는 HTTP 헤더 오버헤드(~400B)가 상대적으로 커서 gRPC가 유리할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 1KB, 10KB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 30초 |

#### 1KB 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **gRPC/Unary** | **5,876.83** | **0.67ms** | 1.19ms | 🥇 |
| gRPC/Stream | 5,822.50 | 0.65ms | 1.17ms | 🥈 |
| HTTP/Binary | 3,695.04 | 1.24ms | 1.88ms | 🥉 |
| HTTP/JSON | 3,428.50 | 1.42ms | 2.14ms | 4위 |

#### 10KB 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **gRPC/Unary** | **5,748.21** | **0.66ms** | 1.16ms | 🥇 |
| gRPC/Stream | 4,412.42 | 1.03ms | 1.85ms | 🥈 |
| HTTP/Binary | 4,026.66 | 1.21ms | 1.88ms | 🥉 |
| HTTP/JSON | 3,168.81 | 1.67ms | 2.43ms | 4위 |

#### 결론
**가설 검증 성공**: 소용량 페이로드에서 gRPC가 HTTP보다 빠름
- 1KB: gRPC가 **59% 더 빠름**
- 10KB: gRPC가 **43% 더 빠름**

#### HTTP 헤더 오버헤드 영향

| 페이로드 | HTTP 헤더 비율 | gRPC 프레이밍 비율 |
|---------|---------------|-------------------|
| 1KB | ~40% | ~5% |
| 10KB | ~4% | ~0.5% |
| 1MB | ~0.04% | ~0.005% |

---

### Phase 3: 고동시성 멀티플렉싱 (50~500 VU)

#### 목적
HTTP/2 멀티플렉싱의 고부하 환경에서의 효과 검증

#### 가설
> "100명 이상 동시 접속 시 HTTP/1.1은 커넥션 풀 한계로 느려지고, gRPC는 멀티플렉싱으로 유리할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 10KB |
| 동시 사용자 (VU) | 50 → 100 → 200 → 500 |
| 테스트 시간 | 각 30초 |

#### VU별 Throughput (req/s)

| VU | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | 승자 |
|----|-----------|-------------|------------|-------------|------|
| 50 | 10,081 | **12,151** | 10,775 | 9,580 | HTTP (+13%) |
| 100 | 11,358 | **13,840** | 13,423 | 11,232 | HTTP (+3%) |
| 200 | 12,573 | 14,147 | **15,388** | 12,339 | **gRPC (+9%)** 🔄 |
| 500 | 12,558 | 14,325 | **16,052** | 11,556 | **gRPC (+12%)** |

#### 결론
**가설 부분 성공**: 역전 포인트는 **100~200 VU 사이**
- 200 VU부터 gRPC가 HTTP를 추월
- 500 VU에서 gRPC Latency p95가 HTTP보다 **36% 더 낮음**

#### 스케일링 특성

| 프로토콜 | 50→500 VU 증가율 | 특성 |
|----------|-----------------|------|
| gRPC/Unary | **+49%** | VU 증가에 가장 잘 대응 |
| HTTP/JSON | +25% | 200 VU부터 포화 |
| HTTP/Binary | +18% | 200 VU부터 포화 |
| gRPC/Stream | +21% | 500 VU에서 감소 |

---

### Phase 4: 역전 포인트 탐색 (10KB~500KB)

#### 목적
gRPC와 HTTP의 성능이 역전되는 페이로드 크기 탐색

#### 가설
> "100KB ~ 500KB 사이에서 HTTP가 gRPC를 추월할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 10KB → 50KB → 100KB → 200KB → 500KB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 각 30초 |

#### 최종 결과: HTTP/Binary vs gRPC/Unary

| 크기 | HTTP/Binary | gRPC/Unary | 차이 | 승자 |
|------|-------------|------------|------|------|
| 10KB | 3,745 | 6,268 | **+67%** | 🏆 gRPC/Unary |
| 50KB | 4,089 | 5,628 | **+38%** | 🏆 gRPC/Unary |
| 100KB | 3,904 | 5,067 | **+30%** | 🏆 gRPC/Unary |
| 200KB | 4,714 | 4,128 | **+14%** | 🏆 HTTP/Binary |
| 500KB | 3,883 | 2,430 | **+60%** | 🏆 HTTP/Binary |

#### 결론
**가설 검증 성공**: 역전 포인트는 **100KB ~ 200KB 사이**
- ≤100KB: gRPC가 30~67% 더 빠름
- ≥200KB: HTTP가 14~60% 더 빠름

#### 역전 원인

| 요인 | 소용량 (≤100KB) | 대용량 (≥200KB) |
|------|----------------|----------------|
| HTTP 헤더 오버헤드 | 상대적으로 큼 | 무시할 수준 |
| Protobuf 직렬화 비용 | 낮음 | **높음** |
| ByteString.copyFrom() | 영향 적음 | **복사 비용 큼** |

---

### Phase 5: 복잡한 데이터 구조 직렬화 (5~50 필드)

#### 목적
JSON 파싱 vs Protobuf 파싱 성능 차이 검증

#### 가설
> "필드가 많고 중첩된 복잡한 객체에서는 gRPC가 유리할 것이다"

#### 테스트 조건

| 복잡도 | 필드 수 | 중첩 깊이 | 배열 요소 |
|--------|--------|----------|----------|
| Simple | 5개 | 0 | 0 |
| Medium | 13개 | 1단계 | 15 |
| Complex | 50개 | 2단계 | 150 |

#### 복잡도별 Throughput (req/s)

| 복잡도 | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | gRPC 우위 |
|--------|-----------|-------------|------------|-------------|-----------|
| Simple | 3,602 | 3,627 | **6,007** | 5,915 | +67% |
| Medium | 3,273 | 3,393 | **5,527** | 3,057 | +69% |
| Complex | 3,154 | 2,955 | **4,415** | 4,400 | +40% |

#### 결론
**가설 부분 확인**: gRPC가 모든 복잡도에서 우위이나, 복잡도가 증가할수록 **격차가 줄어듦** (67% → 40%)

#### 흥미로운 발견
- Complex 데이터에서 **HTTP/Binary < HTTP/JSON** (역전 현상)
- 원인: 복잡한 구조에서 Protobuf over HTTP 빌딩 오버헤드 > JSON 직렬화

---

### Phase 6: 극한 복잡도 역전 탐색 (150~500 필드)

#### 목적
구조적 복잡성만으로 HTTP가 gRPC를 역전하는 포인트 탐색

#### 가설
> "~500개 필드, 4단계 중첩에서 HTTP가 gRPC를 추월할 것이다"

#### 테스트 조건

| 복잡도 | 필드 수 | 중첩 깊이 | 빌더 호출 |
|--------|--------|----------|----------|
| Ultra | ~150개 | 3단계 | ~200회 |
| Extreme | ~500개 | 4단계 | ~800회 |

#### 결과

| 복잡도 | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | 승자 |
|--------|-----------|-------------|------------|-------------|------|
| Ultra | **2,074** | 2,154 | 1,847 | 1,834 | **HTTP/JSON (+12%)** 🔥 |
| Extreme | **419** | 482 | 407 | 408 | **HTTP/JSON (+3%)** 🔥 |

#### 결론
**가설 검증 성공**: 역전 포인트는 예상보다 빨리 **~150 필드**에서 발생
- Ultra에서 HTTP/JSON이 gRPC/Unary보다 **12% 더 빠름**
- Extreme에서도 HTTP가 우위 유지

#### 역전 메커니즘

```
                    빌더 호출 수
                    5회    30회   200회   800회
                    │      │      │       │
gRPC 성능:   ██████████████████████████
                                    ↓ 급락
HTTP 성능:   ████████████████████████████████████
                                    ↑ 역전 발생

원인: Protobuf Builder 객체 생성/해제 비용 누적
```

#### 성능 우위 변화 시각화

```
Simple  (5필드)   : gRPC +67% ████████████████████████████████████
Medium  (13필드)  : gRPC +69% █████████████████████████████████████
Complex (50필드)  : gRPC +40% ███████████████████████
Ultra   (150필드) : HTTP +12% ▓▓▓▓▓▓▓ (역전!)
Extreme (500필드) : HTTP +3%  ▓▓ (역전 유지)
```

---

### Phase 7: CPU 사용량 포함 성능 분석

#### 목적
Phase 6에서 발견한 역전 현상의 원인을 CPU 사용량 관점에서 분석

#### 가설
> "gRPC/Protobuf는 극한 복잡도에서 빌더 객체 생성으로 인해 JSON보다 더 많은 CPU를 사용하며, 이것이 성능 역전의 주된 원인이다"

#### 테스트 조건

| 항목 | 값 |
|------|-----|
| 데이터 복잡도 | Ultra (~150 필드), Extreme (~500 필드) |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 각 30초 |
| CPU 샘플링 간격 | 100ms |
| 테스트 횟수 | 2회 (재현성 검증) |

#### Ultra 복잡도 결과

**Throughput & Latency (2차 테스트 기준)**

| 프로토콜 | Throughput (req/s) | Latency avg | Latency P95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| HTTP/Binary | 2,248 | 3.20ms | 4.35ms | 🥇 |
| **HTTP/JSON** | **2,013** | 3.63ms | 5.18ms | 🥈 |
| gRPC/Stream | 1,913 | 3.63ms | 5.34ms | 🥉 |
| gRPC/Unary | 1,880 | 3.69ms | 5.40ms | 4위 |

**CPU 사용량**

| 프로토콜 | Avg System CPU | Peak System CPU | Avg Process CPU | Peak Process CPU |
|----------|---------------|-----------------|-----------------|------------------|
| HTTP/JSON | 44.0% | 67.7% | **16.8%** | 18.5% |
| HTTP/Binary | 44.6% | 70.2% | **11.9%** | 13.9% |
| gRPC/Unary | 41.7% | 61.6% | **13.8%** | 15.3% |
| gRPC/Stream | 43.8% | 80.2% | **13.8%** | 15.5% |

#### Extreme 복잡도 결과

**Throughput & Latency (2차 테스트 기준)**

| 프로토콜 | Throughput (req/s) | Latency avg | Latency P95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| HTTP/Binary | 455 | 20.40ms | 26.82ms | 🥇 |
| **HTTP/JSON** | **394** | 23.92ms | 30.67ms | 🥈 |
| gRPC/Stream | 402 | 21.67ms | 26.86ms | 🥉 |
| gRPC/Unary | 371 | 23.60ms | 30.57ms | 4위 |

**CPU 사용량**

| 프로토콜 | Avg System CPU | Peak System CPU | Avg Process CPU | Peak Process CPU |
|----------|---------------|-----------------|-----------------|------------------|
| HTTP/JSON | 51.1% | 96.6% | **13.1%** | 14.9% |
| HTTP/Binary | 48.4% | 95.4% | **3.4%** | 4.2% |
| gRPC/Unary | 51.2% | 99.6% | **9.3%** | 11.1% |
| gRPC/Stream | 44.0% | 69.3% | **9.4%** | 10.9% |

#### CPU 효율성 분석

> CPU 효율성 = Throughput / Avg Process CPU  
> (높을수록 CPU 1% 당 더 많은 요청 처리)

| 복잡도 | 프로토콜 | Throughput | Avg Process CPU | 효율성 (req/s/%) | 순위 |
|--------|----------|------------|-----------------|------------------|------|
| Ultra | HTTP/Binary | 2,248 | 11.9% | **188.4** | 🥇 |
| Ultra | gRPC/Stream | 1,913 | 13.8% | 139.1 | 🥈 |
| Ultra | gRPC/Unary | 1,880 | 13.8% | 135.8 | 🥉 |
| Ultra | HTTP/JSON | 2,013 | 16.8% | 120.1 | 4위 |
| Extreme | HTTP/Binary | 455 | 3.4% | **136.0** | 🥇 |
| Extreme | gRPC/Stream | 402 | 9.4% | 42.6 | 🥈 |
| Extreme | gRPC/Unary | 371 | 9.3% | 40.1 | 🥉 |
| Extreme | HTTP/JSON | 394 | 13.1% | 30.0 | 4위 |

#### 재현성 검증 (1차 vs 2차 테스트)

| 복잡도 | 비교 (JSON vs gRPC) | 1차 테스트 | 2차 테스트 | 일관성 |
|--------|---------------------|-----------|-----------|--------|
| Ultra | HTTP/JSON vs gRPC/Unary | +4% | **+7%** | ✅ HTTP 우위 |
| Extreme | HTTP/JSON vs gRPC/Unary | +5% | **+6%** | ✅ HTTP 우위 |

#### 결론
**가설 부분 기각**: CPU 사용량이 역전의 직접적 원인이 아님

| 가설 | 예상 | 실제 결과 | 판정 |
|------|------|----------|------|
| gRPC가 더 많은 CPU 사용 | gRPC > HTTP | **HTTP/JSON이 가장 높음** | ❌ 기각 |
| 빌더 생성이 CPU 집약적 | Process CPU 차이 | **HTTP/JSON이 16.8%로 최고** | ❌ 기각 |
| HTTP가 더 효율적 | HTTP 효율성 > gRPC | **HTTP/Binary만 해당** | ⚠️ 부분 확인 |

#### 새로운 발견

1. **HTTP/Binary가 CPU 효율성 압도적**: 188 vs 136 req/s/% (Ultra)
2. **HTTP/JSON은 높은 CPU 사용에도 gRPC보다 빠름**: 프로토콜 단순성 효과
3. **GC Count와 성능 반비례**: 상관관계 확인, 인과관계는 추가 검증 필요

#### 역전 원인 (추가 검증 필요)

| 기존 가설 | 수정된 분석 |
|----------|------------|
| Protobuf 빌더가 CPU 집약적 | ❌ CPU 사용량은 오히려 낮음 |
| JSON이 CPU 효율적 | ⚠️ HTTP/Binary만 해당 |
| 빌더 호출 수가 핵심 | ⚠️ GC 압박 가설은 추가 검증 필요 |

---

## 🔬 Phase별 설계 문서

각 Phase의 상세 설계는 다음 파일에서 확인할 수 있습니다:
- `PHASE2_DESIGN.md` - 소용량 페이로드 테스트 설계
- `PHASE3_DESIGN.md` - 고동시성 멀티플렉싱 테스트 설계
- `PHASE4_DESIGN.md` - 역전 포인트 탐색 설계
- `PHASE5_DESIGN.md` - 복잡한 데이터 구조 테스트 설계
- `PHASE6_DESIGN.md` - 극한 복잡도 테스트 설계
- `PHASE7_DESIGN.md` - CPU 사용량 분석 설계

---

## 🔮 향후 별도 프로젝트 제안

Phase 7까지의 벤치마크로 핵심 패턴은 확인되었습니다.  
아래 주제들은 별도 프로젝트로 깊이 있게 다룰 수 있습니다:

### 프로젝트 A: GC 압박 가설 검증

**목적:** GC가 실제로 gRPC 성능 저하의 원인인지 인과관계 검증

**테스트 항목:**
- Heap 크기 변경 (256MB / 1GB / 2GB)
- GC 알고리즘 변경 (G1GC / ZGC / Parallel GC)
- GC 로그 상세 분석
- async-profiler로 객체 할당 프로파일링

**예상 소요:** 1~2일

### 프로젝트 B: 네트워크 지연 환경 테스트

**목적:** 실제 네트워크 환경에서 Protobuf 크기 절감 효과 검증

**테스트 항목:**
- tc 명령으로 지연 추가 (10ms / 50ms / 100ms)
- 패킷 손실 시뮬레이션
- 대역폭 제한 환경

**예상 소요:** 1일

### 프로젝트 C: 고동시성 스케일링 테스트

**목적:** VU 증가 시 gRPC 멀티플렉싱 효과 검증

**테스트 항목:**
- VU 50 / 100 / 200 / 500 단계별 테스트
- Connection Pool 설정 최적화
- HTTP/1.1 vs HTTP/2 비교

**예상 소요:** 1일

### 프로젝트 D: 실제 애플리케이션 시나리오

**목적:** DB 조회 등 I/O가 포함된 현실적 시나리오에서 비교

**테스트 항목:**
- DB 조회 + 직렬화 복합 테스트
- 캐시 적용 시나리오
- 마이크로서비스 간 통신 시뮬레이션

**예상 소요:** 2~3일

---

## 📁 프로젝트 구조

```
proto-bench/
├── apiServer/          # Gateway 서버 (Kotlin + Spring Boot)
│   ├── src/
│   └── build.gradle.kts
├── dataServer/         # 데이터 서버 (Kotlin + Spring Boot)
│   ├── src/
│   └── build.gradle.kts
├── scripts/            # k6 테스트 스크립트
│   ├── phase2/
│   ├── phase3/
│   ├── phase4/
│   ├── phase5/
│   ├── phase6/
│   ├── phase7/
│   └── run-*.sh
├── proto/              # gRPC Proto 파일 (공용)
│   └── data.proto
├── results/            # 벤치마크 결과 저장
├── PHASE*_DESIGN.md    # 각 Phase 설계 문서
├── PHASE*_RESULT.md    # 각 Phase 결과 문서
└── README.md
```

---

## 🚀 실행 방법

### 서버 실행

```bash
# 1. dataServer 실행
cd dataServer
./gradlew bootRun

# 2. apiServer 실행 (새 터미널)
cd apiServer
./gradlew bootRun
```

### 테스트 실행

```bash
cd scripts

# Phase 1: 대용량 페이로드
./run-all.sh

# Phase 2: 소용량 페이로드
./run-phase2.sh

# Phase 3: 고동시성
./run-phase3.sh

# Phase 4: 역전 포인트
./run-phase4.sh

# Phase 5: 데이터 복잡도
./run-phase5.sh

# Phase 6: 극한 복잡도
./run-phase6.sh

# Phase 7: CPU 분석
./run-phase7.sh
```

---

## 📈 벤치마크 엔드포인트

### apiServer (포트 8080)

| Method | Endpoint | 설명 |
|--------|----------|------|
| POST | `/benchmark/start` | 측정 시작 |
| GET | `/api/data` | HTTP로 데이터 요청 |
| POST | `/benchmark/end` | 측정 종료 및 결과 반환 |

### dataServer (HTTP 8081, gRPC 9091)

| Method | Endpoint | 설명 |
|--------|----------|------|
| GET | `/data` | HTTP 데이터 응답 |
| gRPC | `DataService/GetData` | gRPC 데이터 응답 |
| gRPC | `DataService/GetDataStream` | gRPC 스트림 응답 |

---

## 🎯 핵심 인사이트

### 1. "gRPC가 항상 빠르다"는 오해

gRPC는 특정 조건에서만 HTTP보다 빠릅니다:
- ✅ 소용량 페이로드 (≤100KB)
- ✅ 고동시성 환경 (200+ VU)
- ✅ 중간 복잡도 데이터 (≤50 필드)

### 2. Protobuf의 양날의 검

Protobuf는 복잡한 객체 직렬화에 효율적이지만:
- ❌ 대용량 바이너리 전송 시 오버헤드 발생
- ❌ 극한 복잡도(500+ 필드)에서 빌더 생성 비용 증가

### 3. HTTP/2 멀티플렉싱의 조건

멀티플렉싱 효과는 고부하에서만 나타납니다:
- 50~100 VU: HTTP/1.1도 충분히 빠름
- 200+ VU: gRPC의 멀티플렉싱이 효과 발휘

### 4. CPU 효율성의 중요성 (Phase 7 발견)

CPU 효율성 관점에서 HTTP/Binary가 압도적:
- HTTP/Binary: 188 req/s/% (Ultra)
- gRPC/Unary: 136 req/s/% (Ultra)
- CPU 리소스 제한 환경에서는 HTTP/Binary가 유리

### 5. 실무 적용 가이드

| 서비스 유형 | 추천 프로토콜 |
|------------|--------------|
| REST API (소용량) | gRPC/Unary |
| 파일 업로드/다운로드 | HTTP/Binary |
| 마이크로서비스 간 통신 | gRPC/Unary |
| 대시보드/관리자 API | HTTP (개발 편의성) |
| 실시간 알림 | gRPC/Stream |
| 극복잡 데이터 처리 | HTTP/Binary |
| CPU 리소스 제한 환경 | HTTP/Binary |

---

## 📄 라이선스

MIT License