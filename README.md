# Proto-Bench

HTTP vs gRPC 프로토콜 성능 비교 벤치마크 프로젝트

## 프로젝트 목적

동일한 조건에서 HTTP와 gRPC의 실제 성능 차이를 측정하고 수치화합니다. 다양한 조건(페이로드 크기, 동시 사용자 수, 데이터 복잡도)에서 각 프로토콜의 성능 특성을 분석하여 실무에서의 프로토콜 선택 가이드를 제공합니다.

## 아키텍처

```
┌─────────┐      ┌─────────────┐      ┌─────────────┐
│   k6    │ ──── │  apiServer  │ ──── │ dataServer  │
│ (Load)  │      │  (Gateway)  │      │  (Data Gen) │
└─────────┘      └─────────────┘      └─────────────┘
                       │                     │
                 HTTP or gRPC          HTTP or gRPC
```

## 기술 스택

- **Language**: Kotlin
- **Framework**: Spring Boot 3.x
- **gRPC**: grpc-kotlin
- **Build**: Gradle (Kotlin DSL)
- **Load Test**: k6 (Grafana)

---

## 📊 전체 벤치마크 결과 요약

### 프로토콜 선택 가이드

| 조건 | 추천 프로토콜 | 성능 차이 | 근거 |
|------|--------------|----------|------|
| **소용량 API (≤100KB)** | gRPC/Unary | 30~67% 더 빠름 | Protobuf 효율 + HTTP 헤더 오버헤드 절감 |
| **대용량 전송 (≥200KB)** | HTTP/Binary | 14~60% 더 빠름 | 직렬화 오버헤드 없음 |
| **고동시성 (200+ VU)** | gRPC/Unary | 9~12% 더 빠름 | HTTP/2 멀티플렉싱 효과 |
| **저동시성 (< 100 VU)** | HTTP/Binary | 3~13% 더 빠름 | 단순한 프로토콜 |
| **복잡한 구조 (≤50 필드)** | gRPC/Unary | 40~69% 더 빠름 | Protobuf 파싱 효율 |
| **극한 복잡도 (≥150 필드)** | HTTP/Binary | 12~18% 더 빠름 | Protobuf 빌더 오버헤드 |
| **실시간 양방향** | gRPC/Stream | - | 기능적 요구 |

### 핵심 역전 포인트

| 기준 | 역전 포인트 | gRPC 우위 | HTTP 우위 |
|------|------------|----------|----------|
| 페이로드 크기 | 100~200KB | ≤100KB | ≥200KB |
| 동시 사용자 | 100~200 VU | 200+ VU | <100 VU |
| 데이터 복잡도 | ~150 필드 | ≤50 필드 | ≥150 필드 |

---

## 📋 Phase별 상세 결과

### Phase 1: 대용량 단일 페이로드 (1MB)

#### 목적
HTTP와 gRPC 프로토콜의 대용량 데이터(1MB) 전송 성능 비교

#### 가설
> "gRPC는 HTTP/2 기반이고 Protobuf를 사용하므로 HTTP/JSON보다 빠를 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 1MB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 30초 |

#### 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **HTTP/Binary** | **2,506.24** | **2.70ms** | **4.00ms** | 🥇 |
| gRPC/Unary | 1,186.64 | 6.87ms | 11.23ms | 🥈 |
| HTTP/JSON | 514.54 | 17.42ms | 23.81ms | 🥉 |
| gRPC/Stream | 210.72 | 44.53ms | 67.08ms | 4위 |

#### 결론
**가설 기각**: 대용량 단일 페이로드에서는 HTTP/Binary가 gRPC보다 **약 2배 빠름**

#### 원인 분석
- HTTP/Binary: 직렬화 오버헤드 없이 raw bytes 그대로 전송
- gRPC: Protobuf 직렬화/역직렬화 비용 + HTTP/2 프레이밍 오버헤드
- 단일 요청에서는 HTTP/2 멀티플렉싱의 이점이 없음

---

### Phase 2: 소용량 페이로드 (1KB, 10KB)

#### 목적
작은 페이로드에서 HTTP 헤더 오버헤드 영향 검증

#### 가설
> "작은 페이로드에서는 HTTP 헤더 오버헤드(~400B)가 상대적으로 커서 gRPC가 유리할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 1KB, 10KB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 30초 |

#### 1KB 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **gRPC/Unary** | **5,876.83** | **0.67ms** | 1.19ms | 🥇 |
| gRPC/Stream | 5,822.50 | 0.65ms | 1.17ms | 🥈 |
| HTTP/Binary | 3,695.04 | 1.24ms | 1.88ms | 🥉 |
| HTTP/JSON | 3,428.50 | 1.42ms | 2.14ms | 4위 |

#### 10KB 결과

| 프로토콜 | Throughput (req/s) | Latency avg | Latency p95 | 순위 |
|----------|-------------------|-------------|-------------|------|
| **gRPC/Unary** | **5,748.21** | **0.66ms** | 1.16ms | 🥇 |
| gRPC/Stream | 4,412.42 | 1.03ms | 1.85ms | 🥈 |
| HTTP/Binary | 4,026.66 | 1.21ms | 1.88ms | 🥉 |
| HTTP/JSON | 3,168.81 | 1.67ms | 2.43ms | 4위 |

#### 결론
**가설 검증 성공**: 소용량 페이로드에서 gRPC가 HTTP보다 빠름
- 1KB: gRPC가 **59% 더 빠름**
- 10KB: gRPC가 **43% 더 빠름**

#### HTTP 헤더 오버헤드 영향

| 페이로드 | HTTP 헤더 비율 | gRPC 프레이밍 비율 |
|---------|---------------|-------------------|
| 1KB | ~40% | ~5% |
| 10KB | ~4% | ~0.5% |
| 1MB | ~0.04% | ~0.005% |

---

### Phase 3: 고동시성 멀티플렉싱 (50~500 VU)

#### 목적
HTTP/2 멀티플렉싱의 고부하 환경에서의 효과 검증

#### 가설
> "100명 이상 동시 접속 시 HTTP/1.1은 커넥션 풀 한계로 느려지고, gRPC는 멀티플렉싱으로 유리할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 10KB |
| 동시 사용자 (VU) | 50 → 100 → 200 → 500 |
| 테스트 시간 | 각 30초 |

#### VU별 Throughput (req/s)

| VU | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | 승자 |
|----|-----------|-------------|------------|-------------|------|
| 50 | 10,081 | **12,151** | 10,775 | 9,580 | HTTP (+13%) |
| 100 | 11,358 | **13,840** | 13,423 | 11,232 | HTTP (+3%) |
| 200 | 12,573 | 14,147 | **15,388** | 12,339 | **gRPC (+9%)** 🔄 |
| 500 | 12,558 | 14,325 | **16,052** | 11,556 | **gRPC (+12%)** |

#### 결론
**가설 부분 성공**: 역전 포인트는 **100~200 VU 사이**
- 200 VU부터 gRPC가 HTTP를 추월
- 500 VU에서 gRPC Latency p95가 HTTP보다 **36% 더 낮음**

#### 스케일링 특성

| 프로토콜 | 50→500 VU 증가율 | 특성 |
|----------|-----------------|------|
| gRPC/Unary | **+49%** | VU 증가에 가장 잘 대응 |
| HTTP/JSON | +25% | 200 VU부터 포화 |
| HTTP/Binary | +18% | 200 VU부터 포화 |
| gRPC/Stream | +21% | 500 VU에서 감소 |

---

### Phase 4: 역전 포인트 탐색 (10KB~500KB)

#### 목적
gRPC와 HTTP의 성능이 역전되는 페이로드 크기 탐색

#### 가설
> "100KB ~ 500KB 사이에서 HTTP가 gRPC를 추월할 것이다"

#### 테스트 조건
| 항목 | 값 |
|------|-----|
| 페이로드 크기 | 10KB → 50KB → 100KB → 200KB → 500KB |
| 동시 사용자 (VU) | 10 |
| 테스트 시간 | 각 30초 |

#### 최종 결과: HTTP/Binary vs gRPC/Unary

| 크기 | HTTP/Binary | gRPC/Unary | 차이 | 승자 |
|------|-------------|------------|------|------|
| 10KB | 3,745 | 6,268 | **+67%** | 🏆 gRPC/Unary |
| 50KB | 4,089 | 5,628 | **+38%** | 🏆 gRPC/Unary |
| 100KB | 3,904 | 5,067 | **+30%** | 🏆 gRPC/Unary |
| 200KB | 4,714 | 4,128 | **+14%** | 🏆 HTTP/Binary |
| 500KB | 3,883 | 2,430 | **+60%** | 🏆 HTTP/Binary |

#### 결론
**가설 검증 성공**: 역전 포인트는 **100KB ~ 200KB 사이**
- ≤100KB: gRPC가 30~67% 더 빠름
- ≥200KB: HTTP가 14~60% 더 빠름

#### 역전 원인

| 요인 | 소용량 (≤100KB) | 대용량 (≥200KB) |
|------|----------------|----------------|
| HTTP 헤더 오버헤드 | 상대적으로 큼 | 무시할 수준 |
| Protobuf 직렬화 비용 | 낮음 | **높음** |
| ByteString.copyFrom() | 영향 적음 | **복사 비용 큼** |

---

### Phase 5: 복잡한 데이터 구조 직렬화 (5~50 필드)

#### 목적
JSON 파싱 vs Protobuf 파싱 성능 차이 검증

#### 가설
> "필드가 많고 중첩된 복잡한 객체에서는 gRPC가 유리할 것이다"

#### 테스트 조건

| 복잡도 | 필드 수 | 중첩 깊이 | 배열 요소 |
|--------|--------|----------|----------|
| Simple | 5개 | 0 | 0 |
| Medium | 13개 | 1단계 | 15 |
| Complex | 50개 | 2단계 | 150 |

#### 복잡도별 Throughput (req/s)

| 복잡도 | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | gRPC 우위 |
|--------|-----------|-------------|------------|-------------|-----------|
| Simple | 3,602 | 3,627 | **6,007** | 5,915 | +67% |
| Medium | 3,273 | 3,393 | **5,527** | 3,057 | +69% |
| Complex | 3,154 | 2,955 | **4,415** | 4,400 | +40% |

#### 결론
**가설 부분 확인**: gRPC가 모든 복잡도에서 우위이나, 복잡도가 증가할수록 **격차가 줄어듦** (67% → 40%)

#### 흥미로운 발견
- Complex 데이터에서 **HTTP/Binary < HTTP/JSON** (역전 현상)
- 원인: 복잡한 구조에서 Protobuf over HTTP 빌딩 오버헤드 > JSON 직렬화

---

### Phase 6: 극한 복잡도 역전 탐색 (150~500 필드)

#### 목적
구조적 복잡성만으로 HTTP가 gRPC를 역전하는 포인트 탐색

#### 가설
> "~500개 필드, 4단계 중첩에서 HTTP가 gRPC를 추월할 것이다"

#### 테스트 조건

| 복잡도 | 필드 수 | 중첩 깊이 | 빌더 호출 |
|--------|--------|----------|----------|
| Ultra | ~150개 | 3단계 | ~200회 |
| Extreme | ~500개 | 4단계 | ~800회 |

#### 결과

| 복잡도 | HTTP/JSON | HTTP/Binary | gRPC/Unary | gRPC/Stream | 승자 |
|--------|-----------|-------------|------------|-------------|------|
| Ultra | **2,074** | 2,154 | 1,847 | 1,834 | **HTTP/JSON (+12%)** 🔥 |
| Extreme | **419** | 482 | 407 | 408 | **HTTP/JSON (+3%)** 🔥 |

#### 결론
**가설 검증 성공**: 역전 포인트는 예상보다 빨리 **~150 필드**에서 발생
- Ultra에서 HTTP/JSON이 gRPC/Unary보다 **12% 더 빠름**
- Extreme에서도 HTTP가 우위 유지

#### 역전 메커니즘

```
                    빌더 호출 수
                    5회    30회   200회   800회
                    │      │      │       │
gRPC 성능:   ██████████████████████████
                                    ↓ 급락
HTTP 성능:   ████████████████████████████████████
                                    ↑ 역전 발생

원인: Protobuf Builder 객체 생성/해제 비용 누적
```

#### 성능 우위 변화 시각화

```
Simple  (5필드)   : gRPC +67% ████████████████████████████████████
Medium  (13필드)  : gRPC +69% █████████████████████████████████████
Complex (50필드)  : gRPC +40% ███████████████████████
Ultra   (150필드) : HTTP +12% ▓▓▓▓▓▓▓ (역전!)
Extreme (500필드) : HTTP +3%  ▓▓ (역전 유지)
```

---

## 🔬 Phase별 설계 문서

각 Phase의 상세 설계는 다음 파일에서 확인할 수 있습니다:
- `PHASE2_DESIGN.md` - 소용량 페이로드 테스트 설계
- `PHASE3_DESIGN.md` - 고동시성 멀티플렉싱 테스트 설계
- `PHASE4_DESIGN.md` - 역전 포인트 탐색 설계
- `PHASE5_DESIGN.md` - 복잡한 데이터 구조 테스트 설계
- `PHASE6_DESIGN.md` - 극한 복잡도 테스트 설계

---

## 📁 프로젝트 구조

```
proto-bench/
├── apiServer/          # Gateway 서버 (Kotlin + Spring Boot)
│   ├── src/
│   └── build.gradle.kts
├── dataServer/         # 데이터 서버 (Kotlin + Spring Boot)
│   ├── src/
│   └── build.gradle.kts
├── scripts/            # k6 테스트 스크립트
│   ├── phase2/
│   ├── phase3/
│   ├── phase4/
│   ├── phase5/
│   ├── phase6/
│   └── run-*.sh
├── proto/              # gRPC Proto 파일 (공용)
│   └── data.proto
├── results/            # 벤치마크 결과 저장
├── PHASE*_DESIGN.md    # 각 Phase 설계 문서
├── PHASE*_RESULT.md    # 각 Phase 결과 문서
└── README.md
```

---

## 🚀 실행 방법

### 서버 실행

```bash
# 1. dataServer 실행
cd dataServer
./gradlew bootRun

# 2. apiServer 실행 (새 터미널)
cd apiServer
./gradlew bootRun
```

### 테스트 실행

```bash
cd scripts

# Phase 1: 대용량 페이로드
./run-all.sh

# Phase 2: 소용량 페이로드
./run-phase2.sh

# Phase 3: 고동시성
./run-phase3.sh

# Phase 4: 역전 포인트
./run-phase4.sh

# Phase 5: 데이터 복잡도
./run-phase5.sh

# Phase 6: 극한 복잡도
./run-phase6.sh
```

---

## 📈 벤치마크 엔드포인트

### apiServer (포트 8080)

| Method | Endpoint | 설명 |
|--------|----------|------|
| POST | `/benchmark/start` | 측정 시작 |
| GET | `/api/data` | HTTP로 데이터 요청 |
| POST | `/benchmark/end` | 측정 종료 및 결과 반환 |

### dataServer (HTTP 8081, gRPC 9091)

| Method | Endpoint | 설명 |
|--------|----------|------|
| GET | `/data` | HTTP 데이터 응답 |
| gRPC | `DataService/GetData` | gRPC 데이터 응답 |
| gRPC | `DataService/GetDataStream` | gRPC 스트림 응답 |

---

## 🎯 핵심 인사이트

### 1. "gRPC가 항상 빠르다"는 오해

gRPC는 특정 조건에서만 HTTP보다 빠릅니다:
- ✅ 소용량 페이로드 (≤100KB)
- ✅ 고동시성 환경 (200+ VU)
- ✅ 중간 복잡도 데이터 (≤50 필드)

### 2. Protobuf의 양날의 검

Protobuf는 복잡한 객체 직렬화에 효율적이지만:
- ❌ 대용량 바이너리 전송 시 오버헤드 발생
- ❌ 극한 복잡도(500+ 필드)에서 빌더 생성 비용 증가

### 3. HTTP/2 멀티플렉싱의 조건

멀티플렉싱 효과는 고부하에서만 나타납니다:
- 50~100 VU: HTTP/1.1도 충분히 빠름
- 200+ VU: gRPC의 멀티플렉싱이 효과 발휘

### 4. 실무 적용 가이드

| 서비스 유형 | 추천 프로토콜 |
|------------|--------------|
| REST API (소용량) | gRPC/Unary |
| 파일 업로드/다운로드 | HTTP/Binary |
| 마이크로서비스 간 통신 | gRPC/Unary |
| 대시보드/관리자 API | HTTP (개발 편의성) |
| 실시간 알림 | gRPC/Stream |
| 극복잡 데이터 처리 | HTTP/Binary |

---

## 📄 라이선스

MIT License